set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree1 <- rpart(target ~ ., data = df_train, control=rpart.control(maxdepth= 3))
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(dplyr)
df = read_csv('midterm.csv')
colSums(is.na(df))
df = subset(df, select = -c(payfix, admtype, asource, preopday, bwght, ecodub92, pt_state, diag_adm, er_mode, obs_hour, nicu_day))
df %>% count(moa)
df %>% filter(sex == 1) %>% count(moa)
df %>% filter((sex == 2) & (age >= 10) & (age <= 19)) %>% count(moa)
df %>% filter((moa == 10) & (sex == 2)) %>% count(provider)
df %>%group_by(sex) %>% summarise(mean = mean(age))
df %>% group_by(moa) %>% summarise(mean = mean(age))
df %>% group_by(provider) %>% summarise(mean = mean(tot))
df %>% filter((sex == 1) & (age >= 10) & (age <= 19)) %>% group_by(provider) %>% summarise(mean = mean(tot))
df %>% group_by(raceethn) %>% summarise(mean = mean(los))
price <- df %>% filter((sex == 1) & (age == 20)) %>% summarise(mean = mean(tot))
stay <- df %>% filter((sex == 1) & (age == 20)) %>% summarise(mean = mean(los))
price / stay
library(caret)
library(rattle)
library(rpart)
median_tot <- df %>% summarise(median = median(tot))
df$target <- case_when(
df$tot <= 21854 ~ "low",
TRUE ~ "high"
)
df$target <- factor(df$target)
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .80,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree1 <- rpart(target ~ ., data = df_train, control=rpart.control(maxdepth= 3))
View(tree1)
fancyRpartPlot(tree_model)
fancyRpartPlot(tree1)
library(tidyverse)
library(dplyr)
df = read_csv('midterm.csv')
median_tot <- df %>% summarise(median = median(tot))
df$target <- case_when(
df$tot <= 21854 ~ "low",
TRUE ~ "high"
)
df$target <- factor(df$target)
splitIndex <- createDataPartition(df$target, p = .90,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree1 <- rpart(target ~ ., data = df_train, control=rpart.control(maxdepth= 3))
fancyRpartPlot(tree1)
barplot(tree1$variable.importance)
plot(tree1)
tree1 <- rpart(target ~ ., data = df_train, control=rpart.control(maxdepth= 3))
tree1 <- rpart(target ~ ., data = df_train, control=rpart.control(maxdepth= 3))
barplot(tree1$variable.importance)
df$sex <- factor(df$sex)
df <- read_csv('midterm.csv')
median_tot <- df %>% summarise(median = median(tot))
df = subset(df, select = c(age, sex, raceethn, provider, moa, mod, admtype, campus, los, target))
View(df)
median_tot <- df %>% summarise(median = median(tot))
df$target <- case_when(
df$tot <= 21854 ~ "low",
TRUE ~ "high"
)
df = subset(df, select = c(age, sex, raceethn, provider, moa, mod, admtype, campus, los, target))
View(df)
df$target <- factor(df$target)
df$sex <- factor(df$sex)
df$raceethn <- factor(df$raceethn)
df$provider <- factor(df$provider)
df$admtype <- factor(df$admtype)
df$campus <- factor(df$campus)
splitIndex <- createDataPartition(df$target, p = .90,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree1 <- rpart(target ~ ., data = df_train, control=rpart.control(maxdepth= 3))
barplot(tree1$variable.importance)
fancyRpartPlot(tree_model)
fancyRpartPlot(tree_1)
fancyRpartPlot(tree1)
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =5)
tree_approach2 <- train(target~., data=df_train,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
df %>% filter((raceethn != ' ') | (admtype != ' '))
splitIndex <- createDataPartition(df$target, p = .90,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree1 <- rpart(target ~ ., data = df_train, control=rpart.control(maxdepth= 3))
barplot(tree1$variable.importance)
fancyRpartPlot(tree1)
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =5)
tree_approach2 <- train(target~., data=df_train,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =5)
tree_approach2 <- train(target~., data=df_train, method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
View(df_test)
tree_approach2 <- train(target~., data=df_train, method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =5)
tree_approach2 <- train(target~., data= df_train, method ="rpart2", trControl =trControl, tuneGrid = tuneGrid)
tuneGrid = expand.grid(maxdepth = 1:3)
trControl = trainControl(method ="cv",number =5)
tree_approach2 <- train(target~., data= df_train, method ="rpart2", trControl =trControl, tuneGrid = tuneGrid)
df %>% na.omit(df)
tuneGrid = expand.grid(maxdepth = 1:3)
trControl = trainControl(method ="cv",number =5)
tree_approach2 <- train(target~., data= df_train, method ="rpart2", trControl =trControl, tuneGrid = tuneGrid)
barplot(tree1$variable.importance)
fancyRpartPlot(tree1)
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =10)
tree_approach2 <- train(target~., data=df_train,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
View(df_test)
View(df)
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =10)
tree_approach2 <- train(target~., data=df,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
tree_approach2 <- train(target~., data=df_train ,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid, na.action=na.roughfix)
tree_approach2 <- train(target~., data=df_train ,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
View(df)
View(df_test)
df %>% filter((raceethn != ' ') | (admtype != ' '))
df %>% na.omit(df$raceethn)
df %>% na.omit((df$raceethn) | (df$admtype))
df %>% na.omit((df$raceethn) | (df$admtype))
df <- read_csv('midterm.csv')
df$target <- case_when(
df$tot <= 21854 ~ "low",
TRUE ~ "high"
)
df = subset(df, select = c(age, sex, raceethn, provider, moa, mod, admtype, campus, los, target))
df$target <- factor(df$target)
df$sex <- factor(df$sex)
df$raceethn <- factor(df$raceethn)
df$provider <- factor(df$provider)
df$admtype <- factor(df$admtype)
df$campus <- factor(df$campus)
View(df)
df %>% na.omit((df$raceethn) | (df$admtype))
View(df)
df <- df %>% na.omit((df$raceethn) | (df$admtype))
splitIndex <- createDataPartition(df$target, p = .90,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree1 <- rpart(target ~ ., data = df_train, control=rpart.control(maxdepth= 3))
barplot(tree1$variable.importance)
fancyRpartPlot(tree1)
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =10)
tree_approach2 <- train(target~., data=df_train ,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
plot(tree_approach2)
library(e1071)
tree2 <- rpart(target ~.,data = df_train,control=rpart.control(maxdepth=5))
pred <- predict(tree2, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "high")
cm$overall[1]
tree_approach2 <- train(target~., data=df_train ,method ="adaboost",trControl =trControl, tuneGrid = tuneGrid)
tuneGrid = expand.grid(maxdepth = 1:10, nIter = 100)
tree_approach2 <- train(target~., data=df_train ,method ="adaboost",trControl =trControl, tuneGrid = tuneGrid)
tree_approach2 <- train(target~., data=df_train ,method ="rpart",trControl =trControl, tuneGrid = tuneGrid)
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =10)
tree_approach2 <- train(target~., data=df_train ,method ="adaboost",trControl =trControl, tuneGrid = tuneGrid)
tree_approach3 <- train(target~., data=df_train ,method ="rf",trControl =trControl, tuneGrid = tuneGrid)
tuneGrid = expand.grid(nIter =2:10, method='cv')
trControl = trainControl(method ="cv",number =10)
tree_approach2 <- train(target~., data=df_train ,method ="adaboost",trControl =trControl, tuneGrid = tuneGrid)
tuneGrid = expand.grid(mtry = 2:8)
trControl = trainControl(method ="cv",number =10)
tree_approach3 <- train(target~., data=df_train ,method ="rf",trControl =trControl, tuneGrid = tuneGrid)
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =10)
tree_approach1 <- train(target~., data=df_train ,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
plot(tree_approach1)
tuneGrid = expand.grid(nIter =2:5, method='cv')
trControl = trainControl(method ="cv",number =10)
tree_approach2 <- train(target~., data=df_train ,method ="adaboost",trControl =trControl, tuneGrid = tuneGrid)
library(e1071)
tree2 <- rpart(target ~.,data = df_train,control=rpart.control(maxdepth=5))
pred <- predict(tree2, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "high")
cm$overall[1]
median(df$los)
mean(df$los)
median(df$los)
mean(df$los)
df$target <- case_when(
df$los <= 4 ~ "short",
TRUE ~ "long"
)
df <- read_csv('midterm.csv')
median_tot <- df %>% summarise(median = median(tot))
df$target <- case_when(
df$los <= 4 ~ "short",
TRUE ~ "long"
)
df = subset(df, select = c(age, sex, raceethn, provider, moa, mod, admtype, campus, tot, target))
df$target <- factor(df$target)
df$sex <- factor(df$sex)
df$raceethn <- factor(df$raceethn)
df$provider <- factor(df$provider)
df$admtype <- factor(df$admtype)
df$campus <- factor(df$campus)
df <- df %>% na.omit((df$raceethn) | (df$admtype))
splitIndex <- createDataPartition(df$target, p = .90,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =10)
tree_approach4 <- train(target~., data=df_train ,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
plot(tree_approach4)
tree3 <- rpart(target ~.,data = df_train,control=rpart.control(maxdepth=4))
pred <- predict(tree3, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "long")
cm$overall[1]
plot(tree_approach1)
plot(tree_approach1)
plot(tree_approach1)
plot(tree_approach2)
plot(tree_approach3)
fancyRpartPlot(tree2)
cm$overall[1]
fancyRpartPlot(tree2)
cm$overall[1]
df <- read_csv('midterm.csv')
median_tot <- df %>% summarise(median = median(tot))
df$target <- case_when(
df$tot <= 21854 ~ "low",
TRUE ~ "high"
)
df = subset(df, select = c(age, sex, raceethn, provider, moa, mod, admtype, campus, los, target))
df$target <- factor(df$target)
df$sex <- factor(df$sex)
df$raceethn <- factor(df$raceethn)
df$provider <- factor(df$provider)
df$admtype <- factor(df$admtype)
df$campus <- factor(df$campus)
df <- df %>% na.omit((df$raceethn) | (df$admtype))
splitIndex <- createDataPartition(df$target, p = .90,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree1 <- rpart(target ~ ., data = df_train, control=rpart.control(maxdepth= 3))
barplot(tree1$variable.importance)
fancyRpartPlot(tree1)
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =10)
tree_approach1 <- train(target~., data=df_train ,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
plot(tree_approach1)
knitr::opts_chunk$set(echo = FALSE)
tuneGrid = expand.grid(nIter =2:5, method='cv')
trControl = trainControl(method ="cv",number =5)
library(tidyverse)
library(dplyr)
library(caret)
library(rattle)
library(rpart)
set.seed(2020)
tuneGrid = expand.grid(mtry = 2:5)
trControl = trainControl(method ="cv",number =5)
tree_approach3 <- train(target~., data=df_train ,method ="rf",trControl =trControl, tuneGrid = tuneGrid)
plot(tree_approach3)
library(e1071)
pred <- predict(tree_approach3, df_test, type = "raw")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "high")
knitr::opts_chunk$set(echo = FALSE)
plot(tree_approach3)
tuneGrid = expand.grid(nIter =2:5, method='cv')
trControl = trainControl(method ="cv",number =5)
tree_approach2 <- train(target~., data=df_train ,method ="adaboost",trControl =trControl, tuneGrid = tuneGrid)
plot(tree_approach2)
plot(tree_approach2)
pred <- predict(tree_approach1, df_test, type = "raw")
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =5)
tree_approach1 <- train(target~., data=df_train ,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
plot(tree_approach1)
library(e1071)
pred <- predict(tree_approach1, df_test, type = "raw")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "high")
View(df_test)
View(df_test)
View(df)
library(tidyverse)
library(dplyr)
df = read_csv('midterm.csv')
View(df)
mysample <- df[sample(1:nrow(df), 50,
replace=FALSE),]
View(mysample)
df <- read_csv('midterm.csv')
mysample <- df[sample(1:nrow(df), 2000,
replace=FALSE),]
median_tot <- df %>% summarise(median = median(tot))
df$target <- case_when(
df$tot <= 21854 ~ "low",
TRUE ~ "high"
)
df = subset(df, select = c(age, sex, raceethn, provider, moa, mod, admtype, campus, los, target))
df$target <- factor(df$target)
df$sex <- factor(df$sex)
df$raceethn <- factor(df$raceethn)
df$provider <- factor(df$provider)
df$admtype <- factor(df$admtype)
df$campus <- factor(df$campus)
df <- df %>% na.omit((df$raceethn) | (df$admtype))
df <- read_csv('midterm.csv')
mysample <- df[sample(1:nrow(df), 2000,
replace=FALSE),]
median_tot <- df %>% summarise(median = median(tot))
df$target <- case_when(
df$tot <= 21854 ~ "low",
TRUE ~ "high"
)
df = subset(mysample, select = c(age, sex, raceethn, provider, moa, mod, admtype, campus, los, target))
df <- read_csv('midterm.csv')
mysample <- df[sample(1:nrow(df), 2000,
replace=FALSE),]
median_tot <- df %>% summarise(median = median(tot))
mysample$target <- case_when(
mysample$tot <= 21854 ~ "low",
TRUE ~ "high"
)
df = subset(mysample, select = c(age, sex, raceethn, provider, moa, mod, admtype, campus, los, target))
df$target <- factor(df$target)
df$sex <- factor(df$sex)
df$raceethn <- factor(df$raceethn)
df$provider <- factor(df$provider)
df$admtype <- factor(df$admtype)
df$campus <- factor(df$campus)
df <- df %>% na.omit((df$raceethn) | (df$admtype))
splitIndex <- createDataPartition(df$target, p = .90,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree1 <- rpart(target ~ ., data = df_train, control=rpart.control(maxdepth= 3))
barplot(tree1$variable.importance)
fancyRpartPlot(tree1)
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =5)
tree_approach1 <- train(target~., data=df_train ,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
plot(tree_approach1)
tuneGrid = expand.grid(nIter =2:5, method='cv')
trControl = trainControl(method ="cv",number =5)
tree_approach2 <- train(target~., data=df_train ,method ="adaboost",trControl =trControl, tuneGrid = tuneGrid)
plot(tree_approach2)
tuneGrid = expand.grid(nIter =2:10, method='cv')
trControl = trainControl(method ="cv",number =5)
tree_approach2 <- train(target~., data=df_train ,method ="adaboost",trControl =trControl, tuneGrid = tuneGrid)
plot(tree_approach2)
tuneGrid = expand.grid(mtry = 2:10)
trControl = trainControl(method ="cv",number =5)
tree_approach3 <- train(target~., data=df_train ,method ="rf",trControl =trControl, tuneGrid = tuneGrid)
library(e1071)
pred <- predict(tree_approach1, df_test, type = "raw")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "high")
cm$overall[1]
tuneGrid = expand.grid(mtry = 2:10)
trControl = trainControl(method ="cv",number =5)
tree_approach3 <- train(target~., data=df_train ,method ="rf",trControl =trControl, tuneGrid = tuneGrid)
tuneGrid = expand.grid(mtry = 2:5)
trControl = trainControl(method ="cv",number =5)
tree_approach3 <- train(target~., data=df_train ,method ="rf",trControl =trControl, tuneGrid = tuneGrid)
plot(tree_approach3)
plot(tree_approach1)
plot(tree_approach2)
plot(tree_approach3)
fancyRpartPlot(tree2)
library(e1071)
pred <- predict(tree_approach1, df_test, type = "raw")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "high")
cm$overall[1]
library(e1071)
tree_model <- rpart(target ~ ., data = df_train, control = rpart.control(maxdepth = 5))
pred <- predict(tree_approach1, df_test, type = "raw")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "high")
cm$overall[1]
fancyRpartPlot(tree_model)
cm$overall[1]
df <- read_csv('midterm.csv')
mysample <- df[sample(1:nrow(df), 2000,
replace=FALSE),]
median_tot <- df %>% summarise(median = median(tot))
mysample$target <- case_when(
mysample$tot <= 21854 ~ "low",
TRUE ~ "high"
)
df = subset(mysample, select = c(age, sex, raceethn, provider, moa, mod, admtype, campus, los, target))
df$target <- factor(df$target)
df$sex <- factor(df$sex)
df$raceethn <- factor(df$raceethn)
df$provider <- factor(df$provider)
df$admtype <- factor(df$admtype)
df$campus <- factor(df$campus)
df <- df %>% na.omit((df$raceethn) | (df$admtype))
splitIndex <- createDataPartition(df$target, p = .90,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree1 <- rpart(target ~ ., data = df_train, control=rpart.control(maxdepth= 3))
barplot(tree1$variable.importance)
fancyRpartPlot(tree1)
fancyRpartPlot(tree3)
df <- read_csv('midterm.csv')
median_tot <- df %>% summarise(median = median(tot))
df$target <- case_when(
df$los <= 4 ~ "short",
TRUE ~ "long"
)
df = subset(df, select = c(age, sex, raceethn, provider, moa, mod, admtype, campus, tot, target))
df$target <- factor(df$target)
df$sex <- factor(df$sex)
df$raceethn <- factor(df$raceethn)
df$provider <- factor(df$provider)
df$admtype <- factor(df$admtype)
df$campus <- factor(df$campus)
df <- df %>% na.omit((df$raceethn) | (df$admtype))
splitIndex <- createDataPartition(df$target, p = .90,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =5)
tree_approach4 <- train(target~., data=df_train ,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
plot(tree_approach4)
tree3 <- rpart(target ~.,data = df_train,control=rpart.control(maxdepth=4))
pred <- predict(tree3, df_test, type = "class")
cm2 <- confusionMatrix(data = pred, reference = df_test$target, positive = "long")
cm2$overall[1]
fancyRpartPlot(tree3)
cm2$overall[1]
plot(tree_approach1)
plot(tree_approach1)
plot(tree_approach2)
plot(tree_approach3)
print(tree_approach1)
model_accuracy <- tree_approach1 & tree_approach2
model_accuracy <- data.frame(tree_approach1, tree_approach2, tree_approach3)
model_accuracy <- data.frame(c(tree_approach1, tree_approach2, tree_approach3))
model_accuracy <- tree_approach1 &
tree_model <- rpart(target ~ ., data = df_train, control = rpart.control(maxdepth = 5))
library(e1071)
tree_model <- rpart(target ~ ., data = df_train, control = rpart.control(maxdepth = 5))
tree_model <- rpart(target ~ ., data = df_train, control = rpart.control(maxdepth = 5))
pred <- predict(tree_approach1, df_test, type = "raw")
model_accuracy <- data.frame(tree_approach1)
library(e1071)
tree_model <- rpart(target ~ ., data = df_train, control = rpart.control(maxdepth = 5))
pred <- predict(tree_approach1, df_test, type = "raw")
model_accuracy <- resamples(list(adaboost = tree_approach2,
forest = tree_approach3,
tree = tree_approach1))
bwplot(model_accuracy)
bwplot(model_accuracy)
bwplot(model_accuracy)
bwplot(model_accuracy)
save.image("~/Enviroment.RData")
load('Enviroment.rda')
load(envir = 'Enviroment.rda')
setwd("C:/Users/student/R/Dan-Barrett23.github.io")
load(envir = 'Enviroment.rda')
load(envir = 'Enviroment')
load('Enviroment.rda')
load("C:/Users/student/Documents/.RData")
load("C:/Users/student/Documents/.RData")
df = read_csv('midterm.csv')
load("C:/Users/student/R/Dan-Barrett23.github.io/Enviroment.RData")
load("C:/Users/student/R/Dan-Barrett23.github.io/Enviroment.RData")
load("C:/Users/student/R/Dan-Barrett23.github.io/Enviroment.RData")
df = read_csv('midterm.csv')
bwplot(model_accuracy)
fancyRpartPlot(tree_model)
cm$overall[1]
load("C:/Users/student/R/Dan-Barrett23.github.io/Enviroment.RData")
df = read_csv('midterm.csv')
tree1 <- rpart(target ~.,data = df_train,control=rpart.control(maxdepth=5))
fancyRpartPlot(tree1)
cm$overall[1]
mysample <- df[sample(1:nrow(df), 2000,
replace=FALSE),]
median_tot <- df %>% summarise(median = median(tot))
mysample$target <- case_when(
mysample$tot <= 21854 ~ "low",
TRUE ~ "high"
)
df = subset(mysample, select = c(age, sex, raceethn, provider, moa, mod, admtype, campus, los, target))
df <- read_csv('midterm.csv')
median_tot <- df %>% summarise(median = median(tot))
df$target <- case_when(
df$los <= 4 ~ "short",
TRUE ~ "long"
)
splitIndex <- createDataPartition(df$target, p = .90,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tuneGrid = expand.grid(maxdepth = 1:10)
trControl = trainControl(method ="cv",number =5)
tree_approach4 <- train(target~., data=df_train ,method ="rpart2",trControl =trControl, tuneGrid = tuneGrid)
